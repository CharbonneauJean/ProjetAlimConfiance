{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlForTraining = \"\"\"\n",
    "select\n",
    "\tins.idinspection,\n",
    "\teta.idetablissement,\n",
    "\teta.departement,\n",
    "\teta.siren,\n",
    "\teta.geores_lat,\n",
    "\teta.geores_lon,\n",
    "\teta.nb_agrements,\n",
    "\teta.nb_inspections,\n",
    "\tCAST (eta.moy_score*10 AS INTEGER) as moy_score,\n",
    "\teta.commune_norm,\n",
    "\tact.idactivite,\n",
    "\tact.categorie_frais,\n",
    "\tCASE \n",
    "      WHEN ins.synthese_eval = 'Très satisfaisant'  THEN 4\n",
    "      WHEN ins.synthese_eval = 'Satisfaisant'  THEN 3\n",
    "      WHEN ins.synthese_eval = 'A améliorer'  THEN 2\n",
    "      WHEN ins.synthese_eval = 'A corriger de manière urgente'  THEN 1\n",
    "\tEND\tas synthese_eval\n",
    "from inspection ins\n",
    "join etablissement eta on ins.idetablissement = eta.idetablissement\n",
    "join activite act on ins.idactivite = act.idactivite\n",
    "order by eta.idetablissement\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35586 entries, 0 to 35585\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   idinspection     35586 non-null  int64  \n",
      " 1   idetablissement  35586 non-null  int64  \n",
      " 2   departement      35586 non-null  int64  \n",
      " 3   siren            35586 non-null  object \n",
      " 4   geores_lat       35586 non-null  float64\n",
      " 5   geores_lon       35586 non-null  float64\n",
      " 6   nb_agrements     35586 non-null  int64  \n",
      " 7   nb_inspections   35586 non-null  int64  \n",
      " 8   moy_score        35586 non-null  int64  \n",
      " 9   commune_norm     35586 non-null  object \n",
      " 10  idactivite       35586 non-null  int64  \n",
      " 11  categorie_frais  35586 non-null  bool   \n",
      " 12  synthese_eval    35586 non-null  int64  \n",
      "dtypes: bool(1), float64(2), int64(8), object(2)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_query(sqlForTraining, model.session.connection())\n",
    "\n",
    "df['moy_score'].astype('int')\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jean\\AppData\\Local\\Temp\\ipykernel_15400\\3709682832.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['categorie_frais'] = X['categorie_frais'].astype('int')\n",
      "C:\\Users\\jean\\AppData\\Local\\Temp\\ipykernel_15400\\3709682832.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['siren'] = labelencoder.fit_transform(X['siren'])\n",
      "C:\\Users\\jean\\AppData\\Local\\Temp\\ipykernel_15400\\3709682832.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['commune_norm'] = labelencoder.fit_transform(X['commune_norm'])\n"
     ]
    }
   ],
   "source": [
    "X = df[[ 'commune_norm', 'geores_lat', 'geores_lon', 'siren', 'categorie_frais', 'nb_agrements', 'nb_inspections', 'departement', 'idactivite']]\n",
    "X['categorie_frais'] = X['categorie_frais'].astype('int')\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "X['siren'] = labelencoder.fit_transform(X['siren'])\n",
    "X['commune_norm'] = labelencoder.fit_transform(X['commune_norm'])\n",
    "\n",
    "y = df['synthese_eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2, 3, 4], dtype=int64), array([  114,  1661, 18812, 14999], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import Rank2D\n",
    "\n",
    "r2D = Rank2D(algorithm='pearson')\n",
    "r2D.fit(X)\n",
    "r2D.transform(X)\n",
    "r2D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.corrcoef(X, rowvar=False))\n",
    "\n",
    "# sns.pairplot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(X[['geores_lat', 'geores_lon']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.target import FeatureCorrelation\n",
    "fc = FeatureCorrelation(method='mutual_info-regression', sort=True)\n",
    "fc.fit(X, y, discrete_features=False)\n",
    "fc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, train_size=0.7, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(yTrain.value_counts(normalize=True))\n",
    "# print(yTest.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdSc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZTrain = stdSc.fit_transform(XTrain)\n",
    "ZTest = stdSc.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# reg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "# reg=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# reg = GradientBoostingClassifier()\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "reg = XGBClassifier(\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=20,\n",
    "    gamma=0,\n",
    "    reg_alpha=0.005,\n",
    "    objective= 'reg:linear',\n",
    "    nthread=6,\n",
    "    scale_pos_weight=99,\n",
    "    seed=27,\n",
    "    verbosity=0,\n",
    "    max_cat_to_onehot=50,\n",
    "    validate_parameters=False\n",
    "    )\n",
    "\n",
    "reg.fit(ZTrain, yTrain)\n",
    "\n",
    "yPred = reg.predict(ZTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import FeatureImportances\n",
    "clfFI = FeatureImportances(reg, relative=False, labels=XTrain.columns)\n",
    "clfFI.fit(ZTrain, yTrain)\n",
    "clfFI.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "clfConfusion = ConfusionMatrix(reg)\n",
    "clfConfusion.score(ZTest, yTest)\n",
    "clfConfusion.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yellowbrick.classifier import DiscriminationThreshold\n",
    "# clfDT = DiscriminationThreshold(reg, argmax='fscore')\n",
    "# clfDT.fit(ZTrain, yTrain)\n",
    "# clfDT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(ZTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump,load\n",
    "\n",
    "# dump(reg,'jean_model.data')\n",
    "# dump(reg,'arthur_model.data')\n",
    "# dump(reg,'aissa_model.data')\n",
    "\n",
    "reg.save_model(\"jean_model.data\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aaf03e452251dd34be7c0211546b3c2d68a9c113be824b513750ef8d1985cab3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('ProjetAlimconfiance': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
